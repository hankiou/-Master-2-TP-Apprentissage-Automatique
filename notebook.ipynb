{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"00000-72889c01-90b3-4418-9827-15aa6b71f4ca","output_cleared":false,"source_hash":"28f8fc59","execution_millis":153954,"execution_start":1604580087468},"source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.utils import to_categorical\n\n#Datasets\nfrom tensorflow.keras.datasets import mnist\n\n\n#Data\n\nnb_dim_in = 784\nnb_classes = 10\nlayer_size = 512\ndropout = 0.3\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train.reshape(60000, nb_dim_in)\nx_test = x_test.reshape(10000, nb_dim_in)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n\nx_train /= 255\nx_test /= 255\n\n#One-hot encoding\ny_train = to_categorical(y_train, nb_classes)\ny_test = to_categorical(y_test, nb_classes)\n\n#Model\nmodel = Sequential()\n\nmodel.add(Dense(layer_size, input_shape=(nb_dim_in, )))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout))\n\nmodel.add(Dense(layer_size))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout))\n\nmodel.add(Dense(nb_classes))\nmodel.add(Activation('softmax'))\n\nlr_schedule = ExponentialDecay(\n    initial_learning_rate=1e-2,\n    decay_steps=10000,\n    decay_rate=0.9)\n\noptimizer = SGD(learning_rate=lr_schedule)\n\nloss = CategoricalCrossentropy(\n    from_logits=False, label_smoothing=0,\n    name='categorical_crossentropy'\n)\n\nmodel.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])\n\nmodel.fit(x_train, y_train, epochs=15, verbose=1,\nvalidation_data=(x_test, y_test))\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])","execution_count":35,"outputs":[{"name":"stdout","text":"Epoch 1/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.6917 - accuracy: 0.8017 - val_loss: 0.2967 - val_accuracy: 0.9139\nEpoch 2/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.3377 - accuracy: 0.9012 - val_loss: 0.2293 - val_accuracy: 0.9334\nEpoch 3/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.2731 - accuracy: 0.9202 - val_loss: 0.1945 - val_accuracy: 0.9431\nEpoch 4/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.2315 - accuracy: 0.9321 - val_loss: 0.1672 - val_accuracy: 0.9497\nEpoch 5/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.2037 - accuracy: 0.9414 - val_loss: 0.1492 - val_accuracy: 0.9548\nEpoch 6/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.1824 - accuracy: 0.9464 - val_loss: 0.1375 - val_accuracy: 0.9575\nEpoch 7/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.1687 - accuracy: 0.9505 - val_loss: 0.1260 - val_accuracy: 0.9616\nEpoch 8/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.1542 - accuracy: 0.9537 - val_loss: 0.1179 - val_accuracy: 0.9631\nEpoch 9/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.1452 - accuracy: 0.9572 - val_loss: 0.1106 - val_accuracy: 0.9654\nEpoch 10/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.1351 - accuracy: 0.9599 - val_loss: 0.1050 - val_accuracy: 0.9668\nEpoch 11/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.1275 - accuracy: 0.9625 - val_loss: 0.1000 - val_accuracy: 0.9686\nEpoch 12/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.1216 - accuracy: 0.9639 - val_loss: 0.0957 - val_accuracy: 0.9692\nEpoch 13/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.1159 - accuracy: 0.9662 - val_loss: 0.0918 - val_accuracy: 0.9708\nEpoch 14/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.1096 - accuracy: 0.9679 - val_loss: 0.0888 - val_accuracy: 0.9713\nEpoch 15/15\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.1056 - accuracy: 0.9684 - val_loss: 0.0859 - val_accuracy: 0.9724\nTest score: 0.08590888977050781\nTest accuracy: 0.9724000096321106\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Accuracy with 15 epoch\n|Dropout / Neurones par couche | 128 | 256 | 512 |\n|:-|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|**.2**|.967|.971|**.972**|\n|**.3**|.965|.970|**.972**|\n|**.4**|.965|.969|.971|\n\nThe best parameters found so far are dropout=0.3 or 0.2 & layer_size=512 with an accuracy of 0.972","metadata":{"tags":[],"cell_id":"00001-4d2036af-eea1-4f0f-b3a6-f66cc78858bd","output_cleared":false}}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"fd4ceff1-8c87-4e59-8283-7f5fe15c2c45","deepnote_execution_queue":[]}}
